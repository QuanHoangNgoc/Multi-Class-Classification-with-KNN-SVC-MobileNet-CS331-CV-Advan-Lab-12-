# ğŸš€ MobileNetV1 on Caltech101

This project implements **MobileNetV1** to classify images from the **Caltech101 dataset** using **TensorFlow** and **Keras**. The model is trained with different configurations to evaluate its performance.

## ğŸ“‚ Dataset  

The **Caltech101 dataset** consists of **101 object categories** and a background category, containing a total of **~9,000 images**. Each category has **40 to 800 images**.  

## ğŸ— Model Architecture  

- ğŸ› **Base Model:** MobileNetV1 (pretrained on **ImageNet**)  
- ğŸ”— **Additional Layers:** Fully connected layers for classification  
- âš¡ **Activation Function:** ReLU  
- ğŸ“ **Batch Normalization:** Applied for faster convergence  
- ğŸ¯ **Loss Function:** Categorical Cross Entropy / Focal Cross Entropy  
- âš™ **Optimizer:** Adam  
- ğŸ“‰ **Learning Rate Scheduling:** ReduceLROnPlateau (optional)  

## ğŸ‹ï¸ Training Configuration  

- ğŸ“¦ **Batch Size:** 32  
- ğŸ”„ **Epochs:** 10+ (can be increased for better results)  
- âš™ **Optimizer:** Adam (alternatives: SGD with momentum, AdamW)  
- âŒ **Loss Function:** Cross Entropy / Focal Loss  
- ğŸ–¼ **Data Augmentation:** Random flipping, rotation, normalization (optional)  

## ğŸ“Š Results  

The model achieves significant improvements in **validation accuracy** during training, demonstrating its ability to **generalize well** to the dataset.  

## ğŸš€ Future Improvements  

- ğŸ— **Implement data augmentation** for better generalization  
- ğŸ“‰ **Use a learning rate scheduler**  
- âš™ **Experiment with different optimizers**  
- â³ **Train for more epochs**  

## ğŸ‘¨â€ğŸ’» Contributors  

- **Quan-Hoang-Ngoc**  
